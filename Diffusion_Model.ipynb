{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Diffusion Model**\n",
        "\n",
        "Building diffusion model using Keras"
      ],
      "metadata": {
        "id": "e5Vxu5iW8tkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.16.2\n",
        "!pip install matplotlib==3.9.2\n",
        "!pip install numpy\n",
        "import os\n",
        "# Suppress oneDNN optimizations and lower TensorFlow logging level\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "metadata": {
        "id": "cCkGew6a9mrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the MNIST data set for training by normalizing the pixel values and reshaping the images to have a single color channel."
      ],
      "metadata": {
        "id": "ROaC6Xya9sEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the data set\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Expand dimensions to match the input shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# Add noise to the data\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "\n",
        "# Clip the values to be within the range [0, 1]\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n"
      ],
      "metadata": {
        "id": "1CaUl7gO9uEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the diffusion model**"
      ],
      "metadata": {
        "id": "xwbz4d6q9-U2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the diffusion model architecture with reduced complexity\n",
        "input_layer = Input(shape=(28, 28, 1))\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x) # Additional layer\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(28*28*64, activation='relu')(x)\n",
        "x = Reshape((28, 28, 64))(x)\n",
        "x = Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x) # Additional layer\n",
        "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
        "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "diffusion_model = Model(input_layer, output_layer)\n",
        "\n",
        "# Compile the model\n",
        "diffusion_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "\n",
        "# Summary of the model\n",
        "diffusion_model.summary()"
      ],
      "metadata": {
        "id": "pD-iALEP-DSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cache and prefetch the data using TensorFlow data pipelines for faster loading\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_noisy, x_train))\n",
        "train_dataset = train_dataset.cache().batch(64).prefetch(tf.data.AUTOTUNE)  # Reduced batch size\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_test_noisy, x_test))\n",
        "val_dataset = val_dataset.cache().batch(64).prefetch(tf.data.AUTOTUNE)  # Reduced batch size"
      ],
      "metadata": {
        "id": "FyediaMS_Ppf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the diffusion model**"
      ],
      "metadata": {
        "id": "VPywFNLK_TGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement early stopping based on validation loss\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping and smaller batch size\n",
        "diffusion_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=20,\n",
        "    shuffle=True,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "SM00dGM1_ZeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the diffusion model**"
      ],
      "metadata": {
        "id": "im2YeG5c_dLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict the denoised images\n",
        "denoised_images = diffusion_model.predict(x_test_noisy)\n",
        "\n",
        "# Visualize the results\n",
        "n = 10  # Number of digits to display\n",
        "plt.figure(figsize=(20, 6))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display noisy\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display denoised\n",
        "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
        "    plt.imshow(denoised_images[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7TRaHe1k_glm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}